{
  "chunk-1d6f70ce3cb0ea8300e98138eafee571": {
    "tokens": 1200,
    "content": "多轮对话中让AI保持长期记忆的8种优化方式篇\n\n来自：\n\nAiGC 面试宝典\n\n宁静致远\n\n· 多轮对话中让 保持长期记忆的 种优化方式篇 AI 8\n\n· 一、前言\n\n· 二、 Agent 如何获取上下文对话信息？\n\n· 2.1 获取全量历史对话\n\n· 2.2 滑动窗口获取最近部分对话内容\n\n· 2.3 获取历史对话中实体信息\n\n· 2.4 利用知识图谱获取历史对话中的实体及其联系\n\n· 2.5 对历史对话进行阶段性总结摘要\n\n· 2.6 需要获取最新对话，又要兼顾较早历史对话\n\n· 2.7 回溯最近和最关键的对话信息\n\n· 2.8 基于向量检索对话信息\n\n· 致谢\n\n一、前言\n\n在基于大模型的 Agent 中，长期记忆的状态维护至关重要，在 OpenAI AI 应用研究主管 Lilian Weng 的 博客《基于大模型的 Agent 构成》 [1] 中，将记忆视为关键的组件之一，下面我将结合 LangChain 中的代 码， 种不同的记忆维护方式在不同场景中的应用。 8\n\n二、 Agent 如何获取上下文对话信息？\n\n2.1 获取全量历史对话\n\n以一般客服场景为例\n\n在电信公司的客服聊天机器人场景中，如果用户在对话中先是询问了账单问题，接着又谈到了网络连接问 题， ConversationBufferMemory 可以用来记住整个与用户的对话历史，可以帮助 AI 在回答网络问题时还 记得账单问题的相关细节，从而提供更连贯的服务。\n\nfrom langchain.memory import ConversationBufferMemory memory = ConversationBufferMemory() memory.save_context({\"input\": \"你好\"}, {\"output\": \"怎么了\"})\n\nvariables = memory.load_memory_variables({})\n\n2.2 滑动窗口获取最近部分对话内容\n\n以商品咨询场景为例\n\n在一个电商平台上，如果用户询问关于特定产品的问题（如手机的电池续航时间），然后又问到了配送方 式， ConversationBufferWindowMemory 可以帮助 AI 只专注于最近的一两个问题（如配送方式），而不 是整个对话历史，以提供更快速和专注的答复。\n\n2024 年 02 月 08 日 10:05\n\n扫码加 查看更多\n\nfrom langchain.memory import ConversationBufferWindowMemory\n\n# 只保留最后1次互动的记忆 memory = ConversationBufferWindowMemory(k=1)\n\n2.3 获取历史对话中实体信息\n\n以法律咨询场景为例\n\n在法律咨询的场景中，客户可能会提到特定的案件名称、相关法律条款或个人信息（如 我在去年的交通 ' 事故中受了伤，想了解关于赔偿的法律建议 ）。 ' ConversationEntityMemory 可以帮助 AI 记住这些关键 实体和实体关系细节，从而在整个对话过程中提供更准确、更个性化的法律建议。\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0) memory = ConversationEntityMemory(llm=llm) _input = {\"input\": \"公众号《LLM应用全栈开发》的作者是莫尔索\"} memory.load_memory_variables(_input) memory.save_context( _input, {\"output\": \"是吗，这个公众号是干嘛的\"} ) print(memory.load_memory_variables({\"input\": \"莫尔索是谁？\"})) # 输出，可以看到提取了实体关系 {'history': 'Human: 公众号《LLM应用全栈开发》的作者是莫尔索 \\n AI: 是吗，这个公众号 是干嘛的', 'entities': {'莫尔索': '《LLM应用全栈开发》的作者。'}}\n\n2.4 利用知识图谱获取历史对话中的实体及其联系\n\n以医疗咨询场景为例\n\n在医疗咨询中，一个病人可能会描述多个症状和过去的医疗历史（如 我有糖尿病史，最近觉得经常口渴 ' 和疲劳 ）。 ' ConversationKGMemory 可以构建一个包含病人症状、疾病历史和可能的健康关联的知识图 谱，从而帮助 AI 提供更全面和深入的医疗建议。\n\nfrom langchain.memory import ConversationKGMemory from langchain.llms import OpenAI llm = OpenAI(temperature=0) memory = ConversationKGMemory(llm=llm) memory.save_context({\"input\": \"小李是程序员\"}, {\"output\": \"知道了，小李是程序员\"}) memory.save_context({\"input\": \"莫尔索是小李的笔名\"}, {\"output\": \"明白，莫尔索是小李 的笔名\"}) variables = memory.load_memory_variables({\"input\": \"告诉我关于小李的信息\"}) print(variables) # 输出 {'history': 'On 小李: 小李 is 程序员. 小李 的笔名 莫尔索.'}\n\n2.5 对历史对话进行阶段性总结摘要\n\n以教育辅导场景为例\n\n在一系列的教育辅导对话中，学生可能会提出不同的数学问题或理解难题（如 我不太理解二次方程的求 ' 解方法 ）。 ' ConversationSummaryMemory 可以帮助 AI 总结之前的辅导内容和学生的疑问点，以",
    "chunk_order_index": 0,
    "full_doc_id": "doc-bb39cd3adcc21658ba161bb45bac6f53",
    "file_path": "pdf_test.pdf",
    "llm_cache_list": [
      "default:extract:491ab84d73f8660f80726902eacf895b",
      "default:extract:6518a9cef4e6c3d8d6c8471307226240"
    ],
    "create_time": 1763807840,
    "update_time": 1763807929,
    "_id": "chunk-1d6f70ce3cb0ea8300e98138eafee571"
  },
  "chunk-b8ed43b094533527831732f14af49e7e": {
    "tokens": 681,
    "content": "is 程序员. 小李 的笔名 莫尔索.'}\n\n2.5 对历史对话进行阶段性总结摘要\n\n以教育辅导场景为例\n\n在一系列的教育辅导对话中，学生可能会提出不同的数学问题或理解难题（如 我不太理解二次方程的求 ' 解方法 ）。 ' ConversationSummaryMemory 可以帮助 AI 总结之前的辅导内容和学生的疑问点，以便在随 后的辅导中提供更针对性的解释和练习 .\n\n2.6 需要获取最新对话，又要兼顾较早历史对话\n\n以技术支持场景为例\n\n在处理一个长期的技术问题时（如软件故障排查），用户可能会在多次对话中提供不同的错误信息和反 馈。 ConversationSummaryBufferMemory 可以帮助 AI 保留最近几次交互的详细信息，同时提供历史问 题处理的摘要，以便于更有效地识别和解决问题。\n\n2.7 回溯最近和最关键的对话信息\n\n以金融咨询场景为例\n\n在金融咨询聊天机器人中，客户可能会提出多个问题，涉及投资、市场动态或个人财务规划（如 我想了 ' 解股市最近的趋势以及如何分配我的投资组合 ）。 ' ConversationTokenBufferMemory 可以帮助 AI 聚焦于 最近和最关键的几个问题，同时避免由于记忆过多而导致的信息混淆。\n\n2.8 基于向量检索对话信息\n\n以了解最新新闻事件为例\n\n用户可能会对特定新闻事件提出问题，如 最近的经济峰会有什么重要决策？ ' '\n\nVectorStoreRetrieverMemory 能够快速从大量历史新闻数据中检索出与当前问题最相关的信息，即使这 些信息在整个对话历史中不是最新的，也能提供及时准确的背景信息和详细报道。\n\nvectorstore = Chroma(embedding_function=OpenAIEmbeddings()) retriever = vectorstore.as_retriever(search_kwargs=dict(k=1)) memory = VectorStoreRetrieverMemory(retriever=retriever)\n\nmemory.save_context({\"input\": \"我喜欢吃火锅\"}, {\"output\": \"听起来很好吃\"}) memory.save_context({\"input\": \"我不喜欢看摔跤比赛\"}, {\"output\": \"我也是\"})\n\nPROMPT_TEMPLATE = \"\"\"以下是人类和 AI 之间的友好对话。AI 话语多且提供了许多来自其上 下文的具体细节。如果 AI 不知道问题的答案，它会诚实地说不知道。\n\n以前对话的相关片段： {history} （如果不相关，你不需要使用这些信息） 当前对话： 人类：{input} AI：\n\n\"\"\"\n\nprompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=PROMPT_TEMPLATE) conversation_with_summary = ConversationChain( llm=llm, prompt=prompt, memory=memory, verbose=True ) print(conversation_with_summary.predict(input=\"你好，我是莫尔索，你叫什么\")) print(conversation_with_summary.predict(input=\"我喜欢的食物是什么？\")) print(conversation_with_summary.predict(input=\"我提到了哪些运动？\"))\n\n知识星球",
    "chunk_order_index": 1,
    "full_doc_id": "doc-bb39cd3adcc21658ba161bb45bac6f53",
    "file_path": "pdf_test.pdf",
    "llm_cache_list": [
      "default:extract:b272acf40bf24d9d42c16d94e3581b04",
      "default:extract:71f701052d744debc20618c8dfef5857"
    ],
    "create_time": 1763807840,
    "update_time": 1763807912,
    "_id": "chunk-b8ed43b094533527831732f14af49e7e"
  },
  "chunk-1cc4ca43c96fd7860359cde001b38a9a": {
    "content": "\nImage Content Analysis:\nImage Path: /Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/pdf_test/docling/images/image_0.png\nCaptions: None\nFootnotes: None\n\nVisual Analysis: The image is a small square graphic with a centered circular element. The circle has a solid black background, and four white Chinese characters '宁静致远' are displayed horizontally inside it in a clean sans-serif font. The composition is minimalistic and symmetric, with no additional visual elements or text. The color scheme is monochromatic (black and white), and the style is flat and modern with uniform lighting, no gradients, or shadows. This image links to the surrounding document content as it represents the contributor name '宁静致远' mentioned in the document's source section ('来自：AiGC 面试宝典 宁静致远'). The document focuses on 8 methods to optimize long-term memory in AI Agents for multi-turn dialogues, including full history retrieval, sliding windows, and entity information extraction.",
    "tokens": 208,
    "full_doc_id": "doc-bb39cd3adcc21658ba161bb45bac6f53",
    "chunk_order_index": 2,
    "file_path": "pdf_test.pdf",
    "llm_cache_list": [
      "default:extract:e1c032bc7f5609d51858205ddf777c10",
      "default:extract:de631566af8d6a57cef354c7ba2ca0ea"
    ],
    "is_multimodal": true,
    "modal_entity_name": "宁静致远 Circular Contributor Icon (image)",
    "original_type": "image",
    "page_idx": 0,
    "create_time": 1763808033,
    "update_time": 1763808072,
    "_id": "chunk-1cc4ca43c96fd7860359cde001b38a9a"
  },
  "chunk-eea71c7954304b31997a0438a528d24c": {
    "content": "\nImage Content Analysis:\nImage Path: /Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/pdf_test/docling/images/image_1.png\nCaptions: None\nFootnotes: None\n\nVisual Analysis: A square QR code is the sole visual element in the image, rendered in high-contrast black and white. It includes three large square position detection markers at the top-left, top-right, and bottom-left corners—each with a black inner square, white border, and outer black border—typical of standard QR codes. The rest of the square consists of a grid of smaller black and white data modules. There are no people, text, or other objects present. The lighting is even, ensuring clear visibility of the code. Contextually, the QR code is associated with the nearby text '扫码加 查看更多' (scan code to add and view more), indicating it allows users to access additional content related to the document’s discussion of LLM conversation memory techniques like ConversationBufferWindowMemory and ConversationKGMemory.",
    "tokens": 210,
    "full_doc_id": "doc-bb39cd3adcc21658ba161bb45bac6f53",
    "chunk_order_index": 3,
    "file_path": "pdf_test.pdf",
    "llm_cache_list": [
      "default:extract:bd70c204a04a091cf6908aef074baab6",
      "default:extract:991f101f0a03a07a71a1451c0750668c"
    ],
    "is_multimodal": true,
    "modal_entity_name": "QR Code for Additional LLM Conversation Memory Resources (image)",
    "original_type": "image",
    "page_idx": 2,
    "create_time": 1763808033,
    "update_time": 1763808072,
    "_id": "chunk-eea71c7954304b31997a0438a528d24c"
  },
  "chunk-7a6f606e0d7db523b1854e88d7a0ce26": {
    "content": "\nImage Content Analysis:\nImage Path: /Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/pdf_test/docling/images/image_2.png\nCaptions: None\nFootnotes: None\n\nVisual Analysis: The image displays a logo with a clean, modern composition. The layout consists of a graphical icon positioned to the left of accompanying text, forming a unified brand identity. Key elements include: a green circular icon with a stylized white interior design (resembling a planet or star pattern), and the Chinese characters '知识星球' (Zhishi Xingqiu, meaning Knowledge Planet) in a dark, legible font to the right of the icon. Colors used are green (icon background), white (icon interior), and dark gray/black (text). The visual style is minimalist, typical of digital platform branding. The logo appears as a watermark or source indicator in a document discussing AI conversation memory mechanisms (e.g., VectorStoreRetrieverMemory) for applications like financial consultation chatbots, linking it to the Knowledge Planet knowledge-sharing platform.",
    "tokens": 215,
    "full_doc_id": "doc-bb39cd3adcc21658ba161bb45bac6f53",
    "chunk_order_index": 4,
    "file_path": "pdf_test.pdf",
    "llm_cache_list": [
      "default:extract:a90b9bfba60483334ae06df635a315c6",
      "default:extract:0b7e562090ee1ebcbe6b37b7b7ab4e9c"
    ],
    "is_multimodal": true,
    "modal_entity_name": "知识星球 Platform Logo (image)",
    "original_type": "image",
    "page_idx": 5,
    "create_time": 1763808033,
    "update_time": 1763808078,
    "_id": "chunk-7a6f606e0d7db523b1854e88d7a0ce26"
  }
}