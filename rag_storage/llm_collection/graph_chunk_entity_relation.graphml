<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d13" for="edge" attr.name="truncate" attr.type="string"/>
<key id="d12" for="edge" attr.name="created_at" attr.type="long"/>
<key id="d11" for="edge" attr.name="file_path" attr.type="string"/>
<key id="d10" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d9" for="edge" attr.name="keywords" attr.type="string"/>
<key id="d8" for="edge" attr.name="description" attr.type="string"/>
<key id="d7" for="edge" attr.name="weight" attr.type="double"/>
<key id="d6" for="node" attr.name="truncate" attr.type="string"/>
<key id="d5" for="node" attr.name="created_at" attr.type="long"/>
<key id="d4" for="node" attr.name="file_path" attr.type="string"/>
<key id="d3" for="node" attr.name="source_id" attr.type="string"/>
<key id="d2" for="node" attr.name="description" attr.type="string"/>
<key id="d1" for="node" attr.name="entity_type" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_id" attr.type="string"/>
<graph edgedefault="undirected"><node id="Prompt Learning">
  <data key="d0">Prompt Learning</data>
  <data key="d1">method</data>
  <data key="d2">Prompt Learning is a technique that provides context and task-related information to help models generate correct outputs, aiming to minimize the number of fine-tuned parameters and computational complexity.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969349</data>
  <data key="d6"></data>
</node>
<node id="Full Fine-Tuning">
  <data key="d0">Full Fine-Tuning</data>
  <data key="d1">method</data>
  <data key="d2">Full Fine-Tuning involves adjusting all parameters of a pre-trained model for specific downstream tasks but is inefficient.&lt;SEP&gt;A method that updates all parameters of the model for each task.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969349</data>
  <data key="d6"></data>
</node>
<node id="Prefix-Tuning">
  <data key="d0">Prefix-Tuning</data>
  <data key="d1">method</data>
  <data key="d2">Prefix-Tuning constructs task-related virtual tokens as a prefix before input tokens and only updates the prefix parameters during training.&lt;SEP&gt;A fine-tuning method that adds continuous prompt vectors (Prefix) to the model input and updates only Prefix parameters.&lt;SEP&gt;A specific method of Prompting discussed in the AiGC Interview Guide.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5&lt;SEP&gt;chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969507</data>
  <data key="d6"></data>
</node>
<node id="Prompt-Tuning">
  <data key="d0">Prompt-Tuning</data>
  <data key="d1">method</data>
  <data key="d2">Prompt-Tuning is a method that involves tuning prompts to adapt pre-trained models to new tasks with minimal parameter updates.&lt;SEP&gt;A fine-tuning method that adds continuous prompt vectors only at the input layer and updates prompt parameters through backpropagation.&lt;SEP&gt;A specific method of Prompting discussed in the AiGC Interview Guide.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5&lt;SEP&gt;chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969507</data>
  <data key="d6"></data>
</node>
<node id="P-Tuning">
  <data key="d0">P-Tuning</data>
  <data key="d1">method</data>
  <data key="d2">P-Tuning is a prompt learning method designed to optimize prompts for better performance on downstream tasks.&lt;SEP&gt;A method addressing how prompt construction in large models significantly impacts downstream task performance.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969349</data>
  <data key="d6"></data>
</node>
<node id="P-Tuning v2">
  <data key="d0">P-Tuning v2</data>
  <data key="d1">method</data>
  <data key="d2">P-Tuning v2 is an advanced version of P-Tuning with improved approaches for prompt learning.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969349</data>
  <data key="d6"></data>
</node>
<node id="BERT">
  <data key="d0">BERT</data>
  <data key="d1">method</data>
  <data key="d2">BERT is a pre-trained model used in examples to learn associations between prompts and tasks, such as sentiment analysis.&lt;SEP&gt;A bidirectional language model that performs well on natural language understanding tasks.&lt;SEP&gt;BERT is a bidirectional language model used for natural language understanding tasks.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969349</data>
  <data key="d6"></data>
</node>
<node id="MLP">
  <data key="d0">MLP</data>
  <data key="d1">method</data>
  <data key="d2">MLP is a structure added before the prefix layer in Prefix-Tuning to decompose the prefix into smaller dimensions.&lt;SEP&gt;A structure added before the Prefix layer to decompose Prefix into lower-dimensional input and MLP combination output, used to prevent training instability.&lt;SEP&gt;MLP is a multi-layer perceptron used as part of the prompt encoder in P-tuning.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969349</data>
  <data key="d6"></data>
</node>
<node id="AiGC Interview Guide">
  <data key="d0">AiGC Interview Guide</data>
  <data key="d1">content</data>
  <data key="d2">AiGC Interview Guide is the source document discussing prompt learning and related methods.&lt;SEP&gt;A document focusing on Prompting techniques, including sections on why Prompting is needed, its definition, advantages, and methods like Prefix-tuning and Prompt-tuning.&lt;SEP&gt;A guide document that includes sections on various topics, including Prompt-tuning.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-b142f8b0f2a2fe8759186a556310d9ec&lt;SEP&gt;chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969506</data>
  <data key="d6"></data>
</node>
<node id="Sentiment Analysis Task">
  <data key="d0">Sentiment Analysis Task</data>
  <data key="d1">task</data>
  <data key="d2">Sentiment Analysis Task is an example where prompt learning converts classification into a fill-in-the-blank task.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969350</data>
  <data key="d6"></data>
</node>
<node id="宁静致远">
  <data key="d0">宁静致远</data>
  <data key="d1">person</data>
  <data key="d2">宁静致远is the author or contributor of the content in the AiGC Interview Guide.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969351</data>
  <data key="d6"></data>
</node>
<node id="Virtual Tokens">
  <data key="d0">Virtual Tokens</data>
  <data key="d1">concept</data>
  <data key="d2">Virtual Tokens are task-related tokens constructed as a prefix in the Prefix-Tuning method.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969351</data>
  <data key="d6"></data>
</node>
<node id="Downstream Tasks">
  <data key="d0">Downstream Tasks</data>
  <data key="d1">concept</data>
  <data key="d2">Downstream Tasks are specific tasks that pre-trained models are adapted to using methods like Prompt Learning.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969351</data>
  <data key="d6"></data>
</node>
<node id="Pre-trained Model">
  <data key="d0">Pre-trained Model</data>
  <data key="d1">concept</data>
  <data key="d2">Pre-trained Model is a model trained on a large dataset, which can be adapted to new tasks using methods like Prompt Learning.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969351</data>
  <data key="d6"></data>
</node>
<node id="Fill-in-the-blank Task">
  <data key="d0">Fill-in-the-blank Task</data>
  <data key="d1">task</data>
  <data key="d2">Fill-in-the-blank Task is a type of task conversion used in Prompt Learning, such as in sentiment analysis with BERT.</data>
  <data key="d3">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969352</data>
  <data key="d6"></data>
</node>
<node id="器">
  <data key="d0">器</data>
  <data key="d1">artifact</data>
  <data key="d2">An artifact that serves as a base or platform for enhancement.</data>
  <data key="d3">chunk-0d0f1dd17108a46bc9eb7b014ed694bd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969352</data>
  <data key="d6"></data>
</node>
<node id="通用知识星球">
  <data key="d0">通用知识星球</data>
  <data key="d1">concept</data>
  <data key="d2">A concept or entity described as a "general knowledge planet" or "universal knowledge sphere".</data>
  <data key="d3">chunk-0d0f1dd17108a46bc9eb7b014ed694bd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969352</data>
  <data key="d6"></data>
</node>
<node id="通用">
  <data key="d0">通用</data>
  <data key="d1">concept</data>
  <data key="d2">A concept meaning "universal" or "general-purpose" used to describe enhancement.</data>
  <data key="d3">chunk-0d0f1dd17108a46bc9eb7b014ed694bd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969352</data>
  <data key="d6"></data>
</node>
<node id="知识星球">
  <data key="d0">知识星球</data>
  <data key="d1">organization</data>
  <data key="d2">A concept meaning "knowledge planet" or "knowledge sphere" that is being enhanced.&lt;SEP&gt;An organization or platform whose name translates to 'Knowledge Planet', represented by four Chinese characters to the right of the icon.</data>
  <data key="d3">chunk-0d0f1dd17108a46bc9eb7b014ed694bd&lt;SEP&gt;chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="P-tuning">
  <data key="d0">P-tuning</data>
  <data key="d1">method</data>
  <data key="d2">P-tuning is a method that converts prompts into learnable embedding layers and uses a prompt encoder to model dependencies between pseudo tokens and provide better initialization.&lt;SEP&gt;A prompt learning technique mentioned in the technical documentation.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969505</data>
  <data key="d6"></data>
</node>
<node id="Prompt Encoder">
  <data key="d0">Prompt Encoder</data>
  <data key="d1">method</data>
  <data key="d2">The prompt encoder is a component of P-tuning, consisting of a bidirectional LSTM and a two-layer MLP, used to process prompt embeddings.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969353</data>
  <data key="d6"></data>
</node>
<node id="P-tuning v2">
  <data key="d0">P-tuning v2</data>
  <data key="d1">method</data>
  <data key="d2">P-tuning v2 is an improved method that uses deep prompt encoding, removes reparameterization encoders, uses different prompt lengths for different tasks, incorporates multi-task learning, and abandons verbalizers.&lt;SEP&gt;A prompt learning technique mentioned in the technical documentation.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969506</data>
  <data key="d6"></data>
</node>
<node id="GPT-3">
  <data key="d0">GPT-3</data>
  <data key="d1">method</data>
  <data key="d2">GPT-3 uses manually constructed templates for in-context learning, but its performance is sensitive to changes in these templates.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969353</data>
  <data key="d6"></data>
</node>
<node id="Fine-tuning">
  <data key="d0">Fine-tuning</data>
  <data key="d1">method</data>
  <data key="d2">Fine-tuning is a method for adapting pre-trained models to downstream tasks, which P-tuning v2 aims to match in performance.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969353</data>
  <data key="d6"></data>
</node>
<node id="Prefix-tuning">
  <data key="d0">Prefix-tuning</data>
  <data key="d1">method</data>
  <data key="d2">Prefix-tuning is a method that adds tunable prompt tokens to the input at each layer, which influenced P-tuning v2's approach.&lt;SEP&gt;A prompt learning technique mentioned in the technical documentation.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969505</data>
  <data key="d6"></data>
</node>
<node id="Prompt Tuning">
  <data key="d0">Prompt Tuning</data>
  <data key="d1">method</data>
  <data key="d2">Prompt Tuning is a method that P-tuning v2 improves upon to work effectively on smaller models and sequence labeling tasks.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969353</data>
  <data key="d6"></data>
</node>
<node id="Verbalizer">
  <data key="d0">Verbalizer</data>
  <data key="d1">concept</data>
  <data key="d2">A verbalizer is a component in prompt learning that maps class labels to meaningful words, which P-tuning v2 abandons in favor of traditional classification.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969354</data>
  <data key="d6"></data>
</node>
<node id="Classification Head">
  <data key="d0">Classification Head</data>
  <data key="d1">method</data>
  <data key="d2">A classification head is used in P-tuning v2 for traditional CLS and token label classification, initialized randomly.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969354</data>
  <data key="d6"></data>
</node>
<node id="Natural Language Understanding">
  <data key="d0">Natural Language Understanding</data>
  <data key="d1">concept</data>
  <data key="d2">Natural Language Understanding is a type of task where GPT series models underperform compared to BERT.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969354</data>
  <data key="d6"></data>
</node>
<node id="In-Context Learning">
  <data key="d0">In-Context Learning</data>
  <data key="d1">method</data>
  <data key="d2">In-context learning is a training approach used by GPT-3 with manually designed templates.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969354</data>
  <data key="d6"></data>
</node>
<node id="Multi-Task Learning">
  <data key="d0">Multi-Task Learning</data>
  <data key="d1">method</data>
  <data key="d2">Multi-task learning is incorporated in P-tuning v2, where prompts are pre-trained on multiple tasks before adapting to downstream tasks.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969354</data>
  <data key="d6"></data>
</node>
<node id="Sequence Labeling Tasks">
  <data key="d0">Sequence Labeling Tasks</data>
  <data key="d1">concept</data>
  <data key="d2">Sequence labeling tasks, such as Named Entity Recognition, are tasks that P-tuning v2 can be adapted to.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969355</data>
  <data key="d6"></data>
</node>
<node id="LSTM">
  <data key="d0">LSTM</data>
  <data key="d1">method</data>
  <data key="d2">Used to model the correlation between prompt vectors in Prompt-Tuning.&lt;SEP&gt;LSTM is a type of recurrent neural network used as part of the prompt encoder in P-tuning.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969355</data>
  <data key="d6"></data>
</node>
<node id="Named Entity Recognition">
  <data key="d0">Named Entity Recognition</data>
  <data key="d1">concept</data>
  <data key="d2">Named Entity Recognition is a specific type of sequence labeling task that P-tuning v2 can be adapted to.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969355</data>
  <data key="d6"></data>
</node>
<node id="Few-Shot Learning">
  <data key="d0">Few-Shot Learning</data>
  <data key="d1">method</data>
  <data key="d2">Few-shot learning is a training scenario where GPT-3's prompt training can significantly improve performance.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969355</data>
  <data key="d6"></data>
</node>
<node id="Zero-Shot Learning">
  <data key="d0">Zero-Shot Learning</data>
  <data key="d1">method</data>
  <data key="d2">Zero-shot learning is a training scenario where GPT-3's prompt training can significantly improve performance.</data>
  <data key="d3">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969355</data>
  <data key="d6"></data>
</node>
<node id="Prefix">
  <data key="d0">Prefix</data>
  <data key="d1">concept</data>
  <data key="d2">Virtual tokens added to the model input, with parameters updated during training while other Transformer parameters are fixed.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969355</data>
  <data key="d6"></data>
</node>
<node id="Transformer">
  <data key="d0">Transformer</data>
  <data key="d1">method</data>
  <data key="d2">A model architecture where other parts remain fixed during Prefix training.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969356</data>
  <data key="d6"></data>
</node>
<node id="GPT">
  <data key="d0">GPT</data>
  <data key="d1">method</data>
  <data key="d2">An autoregressive modeling architecture for which Prefix-Tuning is designed.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969356</data>
  <data key="d6"></data>
</node>
<node id="NLG Tasks">
  <data key="d0">NLG Tasks</data>
  <data key="d1">concept</data>
  <data key="d2">Natural Language Generation tasks, for which Prefix-Tuning is effective.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969356</data>
  <data key="d6"></data>
</node>
<node id="NLU Tasks">
  <data key="d0">NLU Tasks</data>
  <data key="d1">concept</data>
  <data key="d2">Natural Language Understanding tasks, where Prompt-Tuning may perform poorly on normal-sized pre-trained models.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969356</data>
  <data key="d6"></data>
</node>
<node id="Prompt Ensembling">
  <data key="d0">Prompt Ensembling</data>
  <data key="d1">method</data>
  <data key="d2">Training different prompts for the same task simultaneously in one batch, equivalent to training different models at lower cost.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969356</data>
  <data key="d6"></data>
</node>
<node id="Discrete Prompts">
  <data key="d0">Discrete Prompts</data>
  <data key="d1">method</data>
  <data key="d2">Manually designed prompt templates added to the model, which are costly and less effective.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969356</data>
  <data key="d6"></data>
</node>
<node id="Continuous Prompts">
  <data key="d0">Continuous Prompts</data>
  <data key="d1">method</data>
  <data key="d2">Prompts extended to continuous space, with parameters learned through backpropagation rather than manual design.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969357</data>
  <data key="d6"></data>
</node>
<node id="Sequence Length">
  <data key="d0">Sequence Length</data>
  <data key="d1">concept</data>
  <data key="d2">A resource consumed by Prefix-Tuning, leading to additional computational overhead.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969357</data>
  <data key="d6"></data>
</node>
<node id="Training Stability">
  <data key="d0">Training Stability</data>
  <data key="d1">concept</data>
  <data key="d2">A concern addressed by adding an MLP before the Prefix layer to prevent instability from direct parameter updates.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969357</data>
  <data key="d6"></data>
</node>
<node id="Parameter Efficiency">
  <data key="d0">Parameter Efficiency</data>
  <data key="d1">concept</data>
  <data key="d2">An advantage of lightweight fine-tuning methods like Prefix-Tuning and Prompt-Tuning over Full Fine-Tuning.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969357</data>
  <data key="d6"></data>
</node>
<node id="Catastrophic Forgetting">
  <data key="d0">Catastrophic Forgetting</data>
  <data key="d1">concept</data>
  <data key="d2">A problem that Full Fine-Tuning may cause by changing pre-trained model parameters.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969357</data>
  <data key="d6"></data>
</node>
<node id="In Context Learning">
  <data key="d0">In Context Learning</data>
  <data key="d1">method</data>
  <data key="d2">GPT-3 uses manually constructed templates for this learning approach.</data>
  <data key="d3">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969357</data>
  <data key="d6"></data>
</node>
<node id="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)">
  <data key="d0">Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d1">image</data>
  <data key="d2">A technical diagram illustrating the Prompt-tuning workflow, part of the AiGC Interview Guide’s Prompting methods section. It shows input text with task prompts processed by a pre-trained model to produce outputs, supporting explanations of Prompt-tuning’s core idea.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969444</data>
</node>
<node id="QR Code for Extended AiGC Interview Guide Resources (image)">
  <data key="d0">QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d1">image</data>
  <data key="d2">A QR code from the AiGC Interview Guide's Prompting section, allowing users to scan and access more content or add a contact, supporting the guide's coverage of Prompting techniques.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969444</data>
</node>
<node id="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)">
  <data key="d0">Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d1">image</data>
  <data key="d2">Minimalist logo of Zhishi Xingqiu (Knowledge Planet) with a green circle (white inner curve) and adjacent Chinese text. Present in prompt learning technical docs, indicating potential content source.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969444</data>
</node>
<node id="Image Content Analysis">
  <data key="d0">Image Content Analysis</data>
  <data key="d1">method</data>
  <data key="d2">A method used to analyze the content of an image, including its path, captions, footnotes, and visual characteristics.&lt;SEP&gt;Image Content Analysis is the process of describing and interpreting the visual elements of an image.&lt;SEP&gt;A method used to analyze the content of an image, including its path, captions, and footnotes.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd&lt;SEP&gt;chunk-b142f8b0f2a2fe8759186a556310d9ec&lt;SEP&gt;chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969503</data>
  <data key="d6"></data>
</node>
<node id="/Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/28-提示学习(Prompting)篇/docling/images/image_2.png">
  <data key="d0">/Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/28-提示学习(Prompting)篇/docling/images/image_2.png</data>
  <data key="d1">data</data>
  <data key="d2">This is the file path for the image being analyzed.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="Logo">
  <data key="d0">Logo</data>
  <data key="d1">artifact</data>
  <data key="d2">A simple, minimalist logo image with a horizontal layout, featuring a green circular icon and Chinese characters.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="Green Circular Icon">
  <data key="d0">Green Circular Icon</data>
  <data key="d1">artifact</data>
  <data key="d2">A green circular icon containing a white stylized curve, located on the left side of the logo.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="White Stylized Curve">
  <data key="d0">White Stylized Curve</data>
  <data key="d1">artifact</data>
  <data key="d2">A white stylized curve resembling a partial circle or letter 'C' inside the green circular icon.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="Brand Identity Design">
  <data key="d0">Brand Identity Design</data>
  <data key="d1">concept</data>
  <data key="d2">A flat and clean visual style typical for logos and brand representation.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="Prompt Learning Techniques">
  <data key="d0">Prompt Learning Techniques</data>
  <data key="d1">concept</data>
  <data key="d2">A set of techniques discussed in the technical documentation, including Prefix-tuning, P-tuning, and P-tuning v2.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969504</data>
  <data key="d6"></data>
</node>
<node id="Technical Documentation">
  <data key="d0">Technical Documentation</data>
  <data key="d1">content</data>
  <data key="d2">Technical documentation discussing prompt learning techniques where the logo appears.</data>
  <data key="d3">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969506</data>
  <data key="d6"></data>
</node>
<node id="QR Code">
  <data key="d0">QR Code</data>
  <data key="d1">artifact</data>
  <data key="d2">A square-shaped black-and-white matrix barcode with finder squares at three corners and smaller modules arranged in a grid, designed for optical scanning.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969506</data>
  <data key="d6"></data>
</node>
<node id="Prompting">
  <data key="d0">Prompting</data>
  <data key="d1">concept</data>
  <data key="d2">A technique discussed in the AiGC Interview Guide, covering its necessity, definition, advantages, and specific methods.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969506</data>
  <data key="d6"></data>
</node>
<node id="Scan The Code To Add Contact/View More">
  <data key="d0">Scan The Code To Add Contact/View More</data>
  <data key="d1">content</data>
  <data key="d2">Text instructing users to scan the QR code to access extended resources or connect via a mobile scan.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969507</data>
  <data key="d6"></data>
</node>
<node id="Image Path">
  <data key="d0">Image Path</data>
  <data key="d1">data</data>
  <data key="d2">The file path where the image is stored, specifically /Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/28-提示学习(Prompting)篇/docling/images/image_0.png.&lt;SEP&gt;The specific file location of the image being analyzed: /Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/28-提示学习(Prompting)篇/docling/images/image_1.png.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec&lt;SEP&gt;chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969507</data>
  <data key="d6"></data>
</node>
<node id="2D Barcode">
  <data key="d0">2D Barcode</data>
  <data key="d1">artifact</data>
  <data key="d2">A technical term for the QR code, describing it as a two-dimensional barcode that encodes data for optical scanning.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969507</data>
  <data key="d6"></data>
</node>
<node id="URL Or Contact Info">
  <data key="d0">URL Or Contact Info</data>
  <data key="d1">data</data>
  <data key="d2">The type of data likely encoded within the QR code, intended to provide a web link or contact information.</data>
  <data key="d3">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969508</data>
  <data key="d6"></data>
</node>
<node id="Visual Analysis">
  <data key="d0">Visual Analysis</data>
  <data key="d1">method</data>
  <data key="d2">The process of describing and interpreting the visual elements and layout of the image.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969508</data>
  <data key="d6"></data>
</node>
<node id="Technical Diagram">
  <data key="d0">Technical Diagram</data>
  <data key="d1">artifact</data>
  <data key="d2">A diagram that explains the concept of Prompt-tuning as part of the AiGC Interview Guide.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969509</data>
  <data key="d6"></data>
</node>
<node id="Prompt-tuning">
  <data key="d0">Prompt-tuning</data>
  <data key="d1">concept</data>
  <data key="d2">A technique for guiding pre-trained language models using task-specific prompts without full parameter fine-tuning.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969509</data>
  <data key="d6"></data>
</node>
<node id="Input Text">
  <data key="d0">Input Text</data>
  <data key="d1">data</data>
  <data key="d2">The initial text data provided to the system, represented by a box labeled '输入文本'.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969509</data>
  <data key="d6"></data>
</node>
<node id="Add Indicative Prompt">
  <data key="d0">Add Indicative Prompt</data>
  <data key="d1">method</data>
  <data key="d2">The step of inserting a task-specific prompt before the input text to guide the model.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969509</data>
  <data key="d6"></data>
</node>
<node id="Pre-trained Language Model">
  <data key="d0">Pre-trained Language Model</data>
  <data key="d1">artifact</data>
  <data key="d2">A language model that has been pre-trained on a large corpus of text, represented by a neural network icon.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969509</data>
  <data key="d6"></data>
</node>
<node id="Output Result">
  <data key="d0">Output Result</data>
  <data key="d1">data</data>
  <data key="d2">The final output generated by the model after processing the prompted input.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969510</data>
  <data key="d6"></data>
</node>
<node id="Section 4.2">
  <data key="d0">Section 4.2</data>
  <data key="d1">content</data>
  <data key="d2">A specific section of the AiGC Interview Guide titled '指示微调(Prompt-tuning)篇'.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969510</data>
  <data key="d6"></data>
</node>
<node id="Subsection 4.2.2">
  <data key="d0">Subsection 4.2.2</data>
  <data key="d1">content</data>
  <data key="d2">A subsection within section 4.2 that discusses the core idea of Prompt-tuning.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969510</data>
  <data key="d6"></data>
</node>
<node id="指示微调">
  <data key="d0">指示微调</data>
  <data key="d1">concept</data>
  <data key="d2">A technique for guiding pre-trained models using task-specific prompts, as discussed in the AiGC Interview Guide.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969510</data>
  <data key="d6"></data>
</node>
<node id="输入文本">
  <data key="d0">输入文本</data>
  <data key="d1">data</data>
  <data key="d2">The initial input data provided to the system, represented in the diagram.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969510</data>
  <data key="d6"></data>
</node>
<node id="添加指示性提示">
  <data key="d0">添加指示性提示</data>
  <data key="d1">method</data>
  <data key="d2">The action of adding a task-specific prompt before the input text to guide the model.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969511</data>
  <data key="d6"></data>
</node>
<node id="预训练语言模型">
  <data key="d0">预训练语言模型</data>
  <data key="d1">artifact</data>
  <data key="d2">A language model that has been pre-trained, represented with a neural network icon in the diagram.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969511</data>
  <data key="d6"></data>
</node>
<node id="输出结果">
  <data key="d0">输出结果</data>
  <data key="d1">data</data>
  <data key="d2">The final result generated by the model after processing.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969511</data>
  <data key="d6"></data>
</node>
<node id="指示微调(Prompt-tuning)篇">
  <data key="d0">指示微调(Prompt-tuning)篇</data>
  <data key="d1">content</data>
  <data key="d2">The specific section title in the AiGC Interview Guide covering Prompt-tuning.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969511</data>
  <data key="d6"></data>
</node>
<node id="指示微调思路是什么?">
  <data key="d0">指示微调思路是什么?</data>
  <data key="d1">content</data>
  <data key="d2">The specific question addressed in subsection 4.2.2 about the core idea of Prompt-tuning.</data>
  <data key="d3">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d4">28-提示学习（Prompting）篇.pdf</data>
  <data key="d5">1763969511</data>
  <data key="d6"></data>
</node>
<edge source="Prompt Learning" target="Full Fine-Tuning">
  <data key="d7">1.0</data>
  <data key="d8">Prompt Learning is needed because Full Fine-Tuning is inefficient for specific downstream tasks.</data>
  <data key="d9">adaptation,efficiency</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969358</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning" target="Prefix-Tuning">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning is a method under Prompt Learning that constructs virtual tokens as prefixes.</data>
  <data key="d9">methodology,optimization</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969359</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning" target="Prompt-Tuning">
  <data key="d7">1.0</data>
  <data key="d8">Prompt-Tuning is a method under Prompt Learning for tuning prompts with minimal updates.</data>
  <data key="d9">adaptation,methodology</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969360</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning" target="P-Tuning">
  <data key="d7">1.0</data>
  <data key="d8">P-Tuning is a method under Prompt Learning designed to optimize prompts.</data>
  <data key="d9">methodology,optimization</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969361</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning" target="P-Tuning v2">
  <data key="d7">1.0</data>
  <data key="d8">P-Tuning v2 is an advanced method under Prompt Learning.</data>
  <data key="d9">advancement,methodology</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969362</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning" target="Downstream Tasks">
  <data key="d7">1.0</data>
  <data key="d8">Prompt Learning is used to adapt Pre-trained Models to specific Downstream Tasks efficiently.</data>
  <data key="d9">adaptation,application</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969362</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning" target="Pre-trained Model">
  <data key="d7">1.0</data>
  <data key="d8">Prompt Learning utilizes Pre-trained Models and adapts them to new tasks with minimal parameter updates.</data>
  <data key="d9">adaptation,utilization</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969364</data>
  <data key="d13"></data>
</edge>
<edge source="Full Fine-Tuning" target="Prompt-Tuning">
  <data key="d7">2.0</data>
  <data key="d8">Prompt-Tuning is contrasted with Full Fine-Tuning in terms of efficiency and storage.&lt;SEP&gt;Prompt-Tuning does not change pre-trained model parameters, avoiding catastrophic forgetting, unlike Full Fine-Tuning.</data>
  <data key="d9">catastrophic forgetting,comparison,efficiency,parameter preservation</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969359</data>
  <data key="d13"></data>
</edge>
<edge source="Full Fine-Tuning" target="Prefix-Tuning">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning only updates Prefix parameters, whereas Full Fine-Tuning updates all model parameters.</data>
  <data key="d9">method comparison,parameter efficiency</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969368</data>
  <data key="d13"></data>
</edge>
<edge source="Full Fine-Tuning" target="Catastrophic Forgetting">
  <data key="d7">1.0</data>
  <data key="d8">Full Fine-Tuning may cause catastrophic forgetting problems by changing pre-trained model parameters.</data>
  <data key="d9">model limitation,problem cause</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969371</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="MLP">
  <data key="d7">2.0</data>
  <data key="d8">Prefix-Tuning uses an MLP structure before the prefix layer to decompose and optimize parameters.&lt;SEP&gt;Prefix-Tuning adds an MLP structure before the Prefix layer to prevent training instability from directly updating Prefix parameters.</data>
  <data key="d9">architectural enhancement,parameter optimization,structure,training stability</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969360</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Prompt-Tuning">
  <data key="d7">2.0</data>
  <data key="d8">Prompt-Tuning and Prefix-Tuning are compared as distinct prompt learning methods.&lt;SEP&gt;Prompt-Tuning is a simplified version of Prefix-Tuning, adding prompts only at the input layer rather than every layer.</data>
  <data key="d9">architectural difference,comparison,method simplification,methodology</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525&lt;SEP&gt;chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969361</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Virtual Tokens">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning constructs Virtual Tokens as a prefix before input tokens during training.</data>
  <data key="d9">construction,methodology</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969362</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Prefix">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning uses Prefix as virtual tokens added to the model input, with only Prefix parameters updated during training.</data>
  <data key="d9">method implementation,parameter efficiency</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969367</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="GPT">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning is designed for and effective with the GPT architecture for NLG tasks.</data>
  <data key="d9">architecture specificity,method application</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969369</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Discrete Prompts">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning uses 'implicit' prompts that can be learned, unlike manually designed Discrete Prompts which cannot update parameters.</data>
  <data key="d9">implicit prompts,method comparison</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969370</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Sequence Length">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning consumes sequence length, resulting in additional computational overhead.</data>
  <data key="d9">computational overhead,resource consumption</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969372</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Parameter Efficiency">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-Tuning achieves parameter efficiency by updating only Prefix parameters instead of all model parameters.</data>
  <data key="d9">advantage,lightweight fine-tuning</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969373</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="Prompting">
  <data key="d7">1.0</data>
  <data key="d8">Prefix-tuning is presented as a specific method within the broader concept of Prompting in the guide.</data>
  <data key="d9">method,technique inclusion</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969521</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-Tuning" target="QR Code for Extended AiGC Interview Guide Resources (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity Prefix-Tuning belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969524</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-Tuning" target="LSTM">
  <data key="d7">1.0</data>
  <data key="d8">Prompt-Tuning uses LSTM to model the correlation between prompt vectors.</data>
  <data key="d9">architectural component,modeling correlation</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969367</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-Tuning" target="Prompt Ensembling">
  <data key="d7">1.0</data>
  <data key="d8">Prompt-Tuning uses Prompt Ensembling to train different prompts for the same task in one batch, reducing cost compared to model ensemble.</data>
  <data key="d9">cost reduction,training efficiency</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969368</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-Tuning" target="Continuous Prompts">
  <data key="d7">1.0</data>
  <data key="d8">Prompt-Tuning extends prompts to continuous space and learns prompt parameters through backpropagation.</data>
  <data key="d9">method implementation,parameter learning</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969370</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-Tuning" target="Prompting">
  <data key="d7">1.0</data>
  <data key="d8">Prompt-tuning is presented as a specific method within the broader concept of Prompting in the guide.</data>
  <data key="d9">method,technique inclusion</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969521</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-Tuning" target="QR Code for Extended AiGC Interview Guide Resources (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity Prompt-Tuning belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969525</data>
  <data key="d13"></data>
</edge>
<edge source="P-Tuning" target="BERT">
  <data key="d7">1.0</data>
  <data key="d8">P-Tuning addresses the performance gap between GPT and BERT on NLU tasks due to prompt construction.</data>
  <data key="d9">method motivation,performance gap</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969368</data>
  <data key="d13"></data>
</edge>
<edge source="P-Tuning" target="GPT">
  <data key="d7">1.0</data>
  <data key="d8">P-Tuning is needed because prompt construction significantly impacts downstream task performance for GPT models on NLU tasks.</data>
  <data key="d9">method necessity,performance improvement</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969371</data>
  <data key="d13"></data>
</edge>
<edge source="BERT" target="Sentiment Analysis Task">
  <data key="d7">1.0</data>
  <data key="d8">BERT learns associations between prompts and sentiment in the Sentiment Analysis Task.</data>
  <data key="d9">application,learning</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969359</data>
  <data key="d13"></data>
</edge>
<edge source="BERT" target="GPT-3">
  <data key="d7">1.0</data>
  <data key="d8">GPT-3 underperforms compared to BERT on Natural Language Understanding tasks.</data>
  <data key="d9">NLU tasks,performance comparison</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969365</data>
  <data key="d13"></data>
</edge>
<edge source="MLP" target="Prompt Encoder">
  <data key="d7">1.0</data>
  <data key="d8">The prompt encoder in P-tuning consists of a two-layer MLP.</data>
  <data key="d9">architecture,component</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969366</data>
  <data key="d13"></data>
</edge>
<edge source="MLP" target="Training Stability">
  <data key="d7">1.0</data>
  <data key="d8">The MLP structure is added to prevent training instability caused by directly updating Prefix parameters.</data>
  <data key="d9">architectural solution,prevention mechanism</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969370</data>
  <data key="d13"></data>
</edge>
<edge source="AiGC Interview Guide" target="QR Code">
  <data key="d7">1.0</data>
  <data key="d8">The QR code is positioned within the AiGC Interview Guide and serves to provide additional resources related to the document's content.</data>
  <data key="d9">document component,resource access</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969519</data>
  <data key="d13"></data>
</edge>
<edge source="AiGC Interview Guide" target="Prompting">
  <data key="d7">1.0</data>
  <data key="d8">The AiGC Interview Guide focuses on explaining the Prompting technique, including its various aspects and methods.</data>
  <data key="d9">document focus,technique explanation</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969520</data>
  <data key="d13"></data>
</edge>
<edge source="AiGC Interview Guide" target="QR Code for Extended AiGC Interview Guide Resources (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity AiGC Interview Guide belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969522</data>
  <data key="d13"></data>
</edge>
<edge source="AiGC Interview Guide" target="Technical Diagram">
  <data key="d7">1.0</data>
  <data key="d8">The technical diagram is included in and supports the content of the AiGC Interview Guide.</data>
  <data key="d9">inclusion,support</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969525</data>
  <data key="d13"></data>
</edge>
<edge source="AiGC Interview Guide" target="Prompt-tuning">
  <data key="d7">1.0</data>
  <data key="d8">Prompt-tuning is a topic covered within the AiGC Interview Guide.</data>
  <data key="d9">documentation,topic coverage</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969526</data>
  <data key="d13"></data>
</edge>
<edge source="AiGC Interview Guide" target="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity AiGC Interview Guide belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969533</data>
  <data key="d13"></data>
</edge>
<edge source="Sentiment Analysis Task" target="Fill-in-the-blank Task">
  <data key="d7">1.0</data>
  <data key="d8">The Sentiment Analysis Task is converted into a Fill-in-the-blank Task using prompts in Prompt Learning.</data>
  <data key="d9">conversion,methodology</data>
  <data key="d10">chunk-fd95b50939db31ada6dd9a1db4bf5525</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969361</data>
  <data key="d13"></data>
</edge>
<edge source="器" target="通用知识星球">
  <data key="d7">1.0</data>
  <data key="d8">The artifact serves as a base to enhance the general knowledge planet.</data>
  <data key="d9">enhancement,platform</data>
  <data key="d10">chunk-0d0f1dd17108a46bc9eb7b014ed694bd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969361</data>
  <data key="d13"></data>
</edge>
<edge source="器" target="通用">
  <data key="d7">1.0</data>
  <data key="d8">The artifact is used to enhance something to make it universal or general-purpose.</data>
  <data key="d9">enhancement,modification</data>
  <data key="d10">chunk-0d0f1dd17108a46bc9eb7b014ed694bd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969363</data>
  <data key="d13"></data>
</edge>
<edge source="通用" target="知识星球">
  <data key="d7">1.0</data>
  <data key="d8">The universal/general-purpose attribute is applied to the knowledge planet.</data>
  <data key="d9">description,modification</data>
  <data key="d10">chunk-0d0f1dd17108a46bc9eb7b014ed694bd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969362</data>
  <data key="d13"></data>
</edge>
<edge source="知识星球" target="Prompt Learning Techniques">
  <data key="d7">1.0</data>
  <data key="d8">The知识星球platform is the context where content about Prompt Learning Techniques is shared or hosted.</data>
  <data key="d9">content hosting,knowledge sharing</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969512</data>
  <data key="d13"></data>
</edge>
<edge source="知识星球" target="Logo">
  <data key="d7">1.0</data>
  <data key="d8">The Logo features the text '知识星球' (Knowledge Planet) to the right of the icon.</data>
  <data key="d9">brand representation,textual element</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969514</data>
  <data key="d13"></data>
</edge>
<edge source="知识星球" target="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity 知识星球 belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969518</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning" target="Prompt Encoder">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning uses a prompt encoder to model dependencies between pseudo tokens and provide better initialization.</data>
  <data key="d9">component,initialization</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969362</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning" target="P-tuning v2">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 is an improved version of P-tuning designed to achieve performance comparable to fine-tuning across different model sizes and tasks.</data>
  <data key="d9">evolution,improvement</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969365</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning" target="Prompt Learning Techniques">
  <data key="d7">1.0</data>
  <data key="d8">Prompt Learning Techniques include the method of P-tuning.</data>
  <data key="d9">inclusion,technique category</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969514</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning" target="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity P-tuning belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969522</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Encoder" target="LSTM">
  <data key="d7">1.0</data>
  <data key="d8">The prompt encoder in P-tuning consists of a bidirectional LSTM.</data>
  <data key="d9">architecture,component</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969365</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Prefix-tuning">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 adopts deep prompt encoding from Prefix-tuning by adding tunable prompt tokens at each layer.</data>
  <data key="d9">deep prompt encoding,influence</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969363</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Prompt Tuning">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 enhances Prompt Tuning by making it effective on smaller models and extending it to sequence labeling tasks.</data>
  <data key="d9">enhancement,parameter efficiency</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969363</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Verbalizer">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 abandons the use of verbalizers and returns to traditional CLS and token label classification.</data>
  <data key="d9">abandonment,classification paradigm</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969364</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Multi-Task Learning">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 integrates multi-task learning by pre-training on multiple tasks before adapting to downstream tasks.</data>
  <data key="d9">integration,pre-training</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969366</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Classification Head">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 applies a randomly initialized classification head for token-level classification in tasks like sequence labeling.</data>
  <data key="d9">application,token classification</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969367</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Fine-tuning">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 aims to achieve performance comparable to fine-tuning while being parameter-efficient.</data>
  <data key="d9">parameter efficiency,performance goal</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969369</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Sequence Labeling Tasks">
  <data key="d7">1.0</data>
  <data key="d8">P-tuning v2 can be adapted to sequence labeling tasks like Named Entity Recognition.</data>
  <data key="d9">adaptation,task extension</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969370</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Prompt Learning Techniques">
  <data key="d7">1.0</data>
  <data key="d8">Prompt Learning Techniques include the method of P-tuning v2.</data>
  <data key="d9">inclusion,technique category</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969516</data>
  <data key="d13"></data>
</edge>
<edge source="P-tuning v2" target="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity P-tuning v2 belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969524</data>
  <data key="d13"></data>
</edge>
<edge source="GPT-3" target="In-Context Learning">
  <data key="d7">1.0</data>
  <data key="d8">GPT-3 applies in-context learning with manually designed templates, but its performance is highly sensitive to template changes.</data>
  <data key="d9">application,template sensitivity</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969364</data>
  <data key="d13"></data>
</edge>
<edge source="GPT-3" target="Few-Shot Learning">
  <data key="d7">1.0</data>
  <data key="d8">GPT-3's use of prompt training significantly improves its performance in few-shot learning scenarios.</data>
  <data key="d9">performance improvement,training method</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969366</data>
  <data key="d13"></data>
</edge>
<edge source="GPT-3" target="Zero-Shot Learning">
  <data key="d7">1.0</data>
  <data key="d8">GPT-3's use of prompt training significantly improves its performance in zero-shot learning scenarios.</data>
  <data key="d9">performance improvement,training method</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969366</data>
  <data key="d13"></data>
</edge>
<edge source="GPT-3" target="In Context Learning">
  <data key="d7">1.0</data>
  <data key="d8">GPT-3 uses manually constructed templates for in-context learning.</data>
  <data key="d9">method application,template usage</data>
  <data key="d10">chunk-5f2957c82a9261835874879783ba0ae5</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969372</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-tuning" target="Prompt Learning Techniques">
  <data key="d7">1.0</data>
  <data key="d8">Prompt Learning Techniques include the method of Prefix-tuning.</data>
  <data key="d9">inclusion,technique category</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969513</data>
  <data key="d13"></data>
</edge>
<edge source="Prefix-tuning" target="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)">
  <data key="d7">10.0</data>
  <data key="d8">Entity Prefix-tuning belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969521</data>
  <data key="d13"></data>
</edge>
<edge source="Sequence Labeling Tasks" target="Named Entity Recognition">
  <data key="d7">1.0</data>
  <data key="d8">Named Entity Recognition is a specific type of sequence labeling task.</data>
  <data key="d9">categorization,task type</data>
  <data key="d10">chunk-09a1fb296afcab610f9ab16988f2c5f3</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969366</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Image Content Analysis">
  <data key="d7">10.0</data>
  <data key="d8">Entity Image Content Analysis belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969529</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Image Path">
  <data key="d7">10.0</data>
  <data key="d8">Entity Image Path belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969530</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Visual Analysis">
  <data key="d7">10.0</data>
  <data key="d8">Entity Visual Analysis belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969531</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Technical Diagram">
  <data key="d7">10.0</data>
  <data key="d8">Entity Technical Diagram belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969532</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Prompt-tuning">
  <data key="d7">10.0</data>
  <data key="d8">Entity Prompt-tuning belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969532</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Input Text">
  <data key="d7">10.0</data>
  <data key="d8">Entity Input Text belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969534</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Add Indicative Prompt">
  <data key="d7">10.0</data>
  <data key="d8">Entity Add Indicative Prompt belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969534</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Pre-trained Language Model">
  <data key="d7">10.0</data>
  <data key="d8">Entity Pre-trained Language Model belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969535</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Output Result">
  <data key="d7">10.0</data>
  <data key="d8">Entity Output Result belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969535</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Section 4.2">
  <data key="d7">10.0</data>
  <data key="d8">Entity Section 4.2 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969536</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="Subsection 4.2.2">
  <data key="d7">10.0</data>
  <data key="d8">Entity Subsection 4.2.2 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969536</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="指示微调">
  <data key="d7">10.0</data>
  <data key="d8">Entity 指示微调 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969537</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="输入文本">
  <data key="d7">10.0</data>
  <data key="d8">Entity 输入文本 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969538</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="添加指示性提示">
  <data key="d7">10.0</data>
  <data key="d8">Entity 添加指示性提示 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969538</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="预训练语言模型">
  <data key="d7">10.0</data>
  <data key="d8">Entity 预训练语言模型 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969539</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="输出结果">
  <data key="d7">10.0</data>
  <data key="d8">Entity 输出结果 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969540</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="指示微调(Prompt-tuning)篇">
  <data key="d7">10.0</data>
  <data key="d8">Entity 指示微调(Prompt-tuning)篇 belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969540</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)" target="指示微调思路是什么?">
  <data key="d7">10.0</data>
  <data key="d8">Entity 指示微调思路是什么? belongs to Prompt-tuning Workflow Diagram (AiGC Interview Guide Section 4.2) (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969541</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="Image Content Analysis">
  <data key="d7">10.0</data>
  <data key="d8">Entity Image Content Analysis belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969522</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="Prompting">
  <data key="d7">10.0</data>
  <data key="d8">Entity Prompting belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969523</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="QR Code">
  <data key="d7">10.0</data>
  <data key="d8">Entity QR Code belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969524</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="Scan The Code To Add Contact/View More">
  <data key="d7">10.0</data>
  <data key="d8">Entity Scan The Code To Add Contact/View More belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969526</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="Image Path">
  <data key="d7">10.0</data>
  <data key="d8">Entity Image Path belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969528</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="2D Barcode">
  <data key="d7">10.0</data>
  <data key="d8">Entity 2D Barcode belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969529</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code for Extended AiGC Interview Guide Resources (image)" target="URL Or Contact Info">
  <data key="d7">10.0</data>
  <data key="d8">Entity URL Or Contact Info belongs to QR Code for Extended AiGC Interview Guide Resources (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969530</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="Image Content Analysis">
  <data key="d7">10.0</data>
  <data key="d8">Entity Image Content Analysis belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969514</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="/Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/28-提示学习(Prompting)篇/docling/images/image_2.png">
  <data key="d7">10.0</data>
  <data key="d8">Entity /Users/bytedance/PycharmProjects/my_best/langgraph_teach/output/28-提示学习(Prompting)篇/docling/images/image_2.png belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969515</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="Green Circular Icon">
  <data key="d7">10.0</data>
  <data key="d8">Entity Green Circular Icon belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969517</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="White Stylized Curve">
  <data key="d7">10.0</data>
  <data key="d8">Entity White Stylized Curve belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969517</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="Brand Identity Design">
  <data key="d7">10.0</data>
  <data key="d8">Entity Brand Identity Design belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969519</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="Logo">
  <data key="d7">10.0</data>
  <data key="d8">Entity Logo belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969519</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="Prompt Learning Techniques">
  <data key="d7">10.0</data>
  <data key="d8">Entity Prompt Learning Techniques belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969523</data>
  <data key="d13"></data>
</edge>
<edge source="Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)" target="Technical Documentation">
  <data key="d7">10.0</data>
  <data key="d8">Entity Technical Documentation belongs to Zhishi Xingqiu (Knowledge Planet) Brand Logo (image)</data>
  <data key="d9">belongs_to,contained_in,part_of</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">src/data/28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969524</data>
  <data key="d13"></data>
</edge>
<edge source="Image Content Analysis" target="Logo">
  <data key="d7">1.0</data>
  <data key="d8">The Image Content Analysis describes the visual elements and composition of the Logo.</data>
  <data key="d9">analysis,description</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969512</data>
  <data key="d13"></data>
</edge>
<edge source="Image Content Analysis" target="QR Code">
  <data key="d7">1.0</data>
  <data key="d8">The Image Content Analysis describes the QR code's visual characteristics, composition, and purpose.</data>
  <data key="d9">description,visual analysis</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969519</data>
  <data key="d13"></data>
</edge>
<edge source="Logo" target="Green Circular Icon">
  <data key="d7">1.0</data>
  <data key="d8">The Logo contains the Green Circular Icon as a component on its left side.</data>
  <data key="d9">composition,visual element</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969513</data>
  <data key="d13"></data>
</edge>
<edge source="Logo" target="Brand Identity Design">
  <data key="d7">1.0</data>
  <data key="d8">The Logo is designed in a flat and clean style consistent with Brand Identity Design.</data>
  <data key="d9">design principle,styling</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969515</data>
  <data key="d13"></data>
</edge>
<edge source="Logo" target="Technical Documentation">
  <data key="d7">1.0</data>
  <data key="d8">The logo appears within the context of the technical documentation.</data>
  <data key="d9">context,inclusion</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969516</data>
  <data key="d13"></data>
</edge>
<edge source="Green Circular Icon" target="White Stylized Curve">
  <data key="d7">1.0</data>
  <data key="d8">The Green Circular Icon contains the White Stylized Curve.</data>
  <data key="d9">composition,visual element</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969514</data>
  <data key="d13"></data>
</edge>
<edge source="Prompt Learning Techniques" target="Technical Documentation">
  <data key="d7">1.0</data>
  <data key="d8">The technical documentation discusses prompt learning techniques.</data>
  <data key="d9">content,discussion</data>
  <data key="d10">chunk-f52e4a41f04f4152e6ef4402bb6b39fd</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969517</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code" target="Scan The Code To Add Contact/View More">
  <data key="d7">1.0</data>
  <data key="d8">The QR code is associated with the text instruction, indicating its purpose to be scanned for accessing more resources.</data>
  <data key="d9">functional association,instruction</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969521</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code" target="2D Barcode">
  <data key="d7">1.0</data>
  <data key="d8">The QR code is technically classified as a type of 2D barcode.</data>
  <data key="d9">synonym,technical classification</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969521</data>
  <data key="d13"></data>
</edge>
<edge source="QR Code" target="URL Or Contact Info">
  <data key="d7">1.0</data>
  <data key="d8">The QR code encodes data, which is likely a URL or contact information, defining its primary function.</data>
  <data key="d9">data encoding,functional purpose</data>
  <data key="d10">chunk-b142f8b0f2a2fe8759186a556310d9ec</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969522</data>
  <data key="d13"></data>
</edge>
<edge source="Technical Diagram" target="Prompt-tuning">
  <data key="d7">1.0</data>
  <data key="d8">The technical diagram visually explains the concept and workflow of Prompt-tuning.</data>
  <data key="d9">explanation,visualization</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969525</data>
  <data key="d13"></data>
</edge>
<edge source="Technical Diagram" target="Subsection 4.2.2">
  <data key="d7">1.0</data>
  <data key="d8">The diagram specifically illustrates and simplifies the core idea of Prompt-tuning discussed in subsection 4.2.2.</data>
  <data key="d9">illustration,simplification</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969528</data>
  <data key="d13"></data>
</edge>
<edge source="Technical Diagram" target="Section 4.2">
  <data key="d7">1.0</data>
  <data key="d8">The technical diagram aligns with and visually supports the concepts discussed in Section 4.2 of the guide.</data>
  <data key="d9">conceptual alignment,visual support</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969529</data>
  <data key="d13"></data>
</edge>
<edge source="Input Text" target="Add Indicative Prompt">
  <data key="d7">1.0</data>
  <data key="d8">The Add Indicative Prompt step modifies the Input Text by prepending a task-specific prompt to guide the model.</data>
  <data key="d9">guidance,modification</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969526</data>
  <data key="d13"></data>
</edge>
<edge source="Pre-trained Language Model" target="Output Result">
  <data key="d7">1.0</data>
  <data key="d8">The Pre-trained Language Model processes the prompted input to generate the Output Result.</data>
  <data key="d9">generation,processing</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969526</data>
  <data key="d13"></data>
</edge>
<edge source="Section 4.2" target="Subsection 4.2.2">
  <data key="d7">1.0</data>
  <data key="d8">Subsection 4.2.2 is a part of Section 4.2 in the AiGC Interview Guide.</data>
  <data key="d9">content organization,hierarchical structure</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969527</data>
  <data key="d13"></data>
</edge>
<edge source="输入文本" target="添加指示性提示">
  <data key="d7">1.0</data>
  <data key="d8">The input text is modified by having an indicative prompt added to it.</data>
  <data key="d9">modification,preparation</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969528</data>
  <data key="d13"></data>
</edge>
<edge source="添加指示性提示" target="预训练语言模型">
  <data key="d7">1.0</data>
  <data key="d8">The prompted input is fed into the pre-trained language model for processing.</data>
  <data key="d9">guidance,input</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969529</data>
  <data key="d13"></data>
</edge>
<edge source="预训练语言模型" target="输出结果">
  <data key="d7">1.0</data>
  <data key="d8">The pre-trained language model generates the output result based on the prompted input.</data>
  <data key="d9">generation,output</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969528</data>
  <data key="d13"></data>
</edge>
<edge source="指示微调(Prompt-tuning)篇" target="指示微调思路是什么?">
  <data key="d7">1.0</data>
  <data key="d8">The subsection '指示微调思路是什么?' is part of the section '指示微调(Prompt-tuning)篇'.</data>
  <data key="d9">content structure,question addressing</data>
  <data key="d10">chunk-37058a66b7af8c253ad6a706d8ecd07f</data>
  <data key="d11">28-提示学习（Prompting）篇.pdf</data>
  <data key="d12">1763969529</data>
  <data key="d13"></data>
</edge>
</graph></graphml>