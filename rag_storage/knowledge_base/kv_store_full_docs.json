{
  "doc-59bf9db71eb0feb149a8555e062d5c81": {
    "content": "提示学习（Prompting）篇\n\n来自：\n\nAiGC 面试宝典\n\n宁静致远\n\n· 提示学习（ Prompting ）\n\n· 一、为什么需要提示学习（ Prompting ）？\n\n· 二、什么是提示学习（ Prompting ）？\n\n· 三、提示学习（ Prompting ）有什么优点？\n\n· 四、提示学习（ Prompting ）有哪些方法，能不能稍微介绍一下它们间？\n\n· 4.1 前缀微调（ Prefix-tining ）篇\n\n· 4.1.1 为什么需要前缀微调（ Prefix-tining ）？\n\n· 4.1.2 前缀微调（ Prefix-tining ）思路是什么？\n\n· 4.1.3 前缀微调（ Prefix-tining ）的优点是什么？\n\n· 4.1.4 前缀微调（ Prefix-tining ）的缺点是什么？\n\n· 4.2 指示微调（ Prompt-tuning ）篇\n\n· 4.2.1 为什么需要指示微调（ Prompt-tuning ）？\n\n· 4.2.2 指示微调（ Prompt-tuning ）思路是什么？\n\n· 4.2.3 指示微调（ Prompt-tuning ）优点是什么？\n\n· 4.2.4 指示微调（ Prompt-tuning ）缺点是什么？\n\n· 4.2.5 指示微调（ Prompt-tuning ）与 Prefix-tuning 区别是什么？\n\n· 4.2.6 指示微调（ Prompt-tuning ）与 fine-tuning 区别是什么？\n\n· 4.3 P-tuning 篇\n\n· 4.3.1 为什么需要 P-tuning ？\n\n· 4.3.2 P-tuning 思路是什么？\n\n· 4.3.3 P-tuning 优点是什么？\n\n· 4.3.4 P-tuning 缺点是什么？\n\n· 4.3.5 大模型微调 p_tuning 和传统 fine tuning 有什么区别？\n\n· 4.4 P-tuning v2 篇\n\n· 4.4.1 为什么需要 P-tuning v2 ？\n\n· 4.4.2 P-tuning v2 思路是什么？\n\n· 4.4.3 P-tuning v2 优点是什么？\n\n· 4.4.4 P-tuning v2 缺点是什么？\n\n一、为什么需要提示学习（ Prompting ）？\n\n在面对特定的下游任务时， 如果进行 Full FineTuning （即对预训练模型中的所有参数都进行微调），太过低\n\n效 ；而 如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果\n\n。\n\n二、什么是提示学习（ Prompting ）？\n\nPrompt 提供上下文和任务相关信息，以帮助模型更好地理解要求，并生成正确的输出 。\n\n实例一：问答任务中， prompt 可能包含问题或话题的描述，以帮助模型生成正确的答案\n\n实例二：在情感分析任务中，让模型做情感分类任务的做法通常是在句子前面加入前缀 该句子的情感是 即可， ' ' 通过这种方式将情感分类任务转换为一个填空任务，在训练过程中， ' ' BERT 可以学习到这个前缀与句子情感之 间的关联。例如，它可以学习到 该句子的情感是积极的 和 该句子的情感是消极的 之间的差异。 ' ' ' '\n\n2023 年 09 月 18 日 20:58\n\n扫码加\n\n查看更多\n\n三、提示学习（ Prompting ）有什么优点？\n\n提示学习（ Prompting ）旨在 通过最小化微调参数的数量和计算复杂度，来提高预训练模型在新任务上的性能，\n\n从而缓解大型预训练模型的训练成本 。这样一来，即使计算资源受限，也可以利用预训练模型的知识来迅速适应 新任务，实现高效的迁移学习。\n\n四、提示学习（ Prompting ）有哪些方法，能不能稍微介绍一下它们间？\n\n4.1 前缀微调（ Prefix-tining ）篇\n\n4.1.1 为什么需要前缀微调（ Prefix-tining ）？\n\n1. 人工设计离散的 Prompts 缺点：\n\na. Prompts 的变化对模型最终的性能特别敏感 ，加一个词、少一个词或者变动位置都会造成比较大的 变化\n\n2. 自动化搜索离散的 Prompts 缺点：\n\na. 成本也比较高\n\n3. 离散化的 token 搜索出来的结果可能并不是最优的 ；\n\n4. 传统的微调范式利用预训练模型去对不同的下游任务进行微调，对每个任务都要保存一份微调后的模型权\n\n重 ，一方面微调整个模型耗时长；另一方面也会占很多存储空间\n\n4.1.2 前缀微调（ Prefix-tining ）思路是什么？\n\n· step 1 Prefix 构建 。 在输入 token 之前构造一段任务相关的 virtual tokens 作为 Prefix ；\n\n· step 2 训练时只更新 Prefix 部分的参数 ，而 Transformer 中的其他部分参数固定；\n\n· step 3 在 Prefix 层前面加了 MLP 结构 ( 相当于将 Prefix 分解为更小维度的 Input 与 MLP 的组合后输出的结果 ，训 ) 练完成后，只保留 Prefix 的参数；（用于防止直接更新 Prefix 的参数导致训练不稳定的情况）\n\n4.1.3 前缀微调（ Prefix-tining ）的优点是什么？\n\n1. 前缀微调（ Prefix-tining ） vs 人工设计离散的 Prompts 无法更新参数： 前缀微调（ Prefix-tining ）可以学习 的 隐式 的 ' ' Prompts ；\n\n2. 基于前缀的架构 可以在一个批次中处理来自多个用户任务的样本 / ，这是其他轻量级微调方法所不能做到的；\n\n3. vs full fine-tuning ： full fine-tuning 更新所有参数， Prefix Tuning 只更新 Prefix 部分的参数\n\n；\n\n4.1.4 前缀微调（ Prefix-tining ）的缺点是什么？\n\n1. 占用序列长度 。有一定的额外计算开销 ;\n\n2. 在每层都加了 prompt 的参数，改动较大 ;\n\n4.2 指示微调（ Prompt-tuning ）篇\n\n4.2.1 为什么需要指示微调（ Prompt-tuning ）？\n\n1. 模型全量微调对每个任务训练一个模型，开销和部署成本都比较高 ；\n\n2. 离散的 prompts （指人工设计 prompts 提示语加入到模型）方法，成本比较高，并且效果不太好 ；\n\n3. 前缀微调（ Prefix-tining ）占用序列长度 。有一定的额外计算开销 ;\n\n4. 前缀微调（ Prefix-tining ）在每层都加了 prompt 的参数，改动较大 ;\n\n4.2.2 指示微调（ Prompt-tuning ）思路是什么？\n\n1. 将 prompt 扩展到连续空间， 仅在输入层添加 prompt 连续向量 ，通过反向传播更新参数来学习 prompts ，而 不是人工设计 prompts ；\n\n2. 冻结模型原始权重，只训练 prompts 参数 ，训练完成后，只用同一个模型可以做多任务推理；\n\n3. 使用 LSTM 建模 prompt 向量间关联性\n\n4.2.3 指示微调（ Prompt-tuning ）优点是什么？\n\n1. 只在输入层加入 prompt tokens ，并且 不需要加入 MLP 进行调整来解决难训练的问题 ；\n\n2. 随着预训练模型参数量的增加， Prompt Tuning 的方法会逼近全参数微调的结果 ;\n\n3. 提出了 prompt ensembling ：在一个批次（ Batch ）里同时训练同一个任务的不同 prompt （即采用多种不同方 式询问同一个问题），这样相当于训练了不同模型，比模型集成的成本小多了；\n\n4.2.4 指示微调（ Prompt-tuning ）缺点是什么？\n\n1. 训练难度加大 。不太好训练，省了显存，但不一定省时间。具体来讲，大部分 prompt 现在只是 parameter efficient 并没有达到想要的 training efficient 。也就是说只是省了空间 显存 ，但不一定能加快训练，训练时间 ( ) 有可能更长\n\n2. 多个 prompt token 之间相互独立，可能会影响效果\n\n3. 在 NLU 上， prompt tuning 对于正常大小的预训练模型表现不佳；\n\n4. 现有的 prompt tuning 方法不能处理困难的序列标注任务\n\n4.2.5 指示微调（ Prompt-tuning ）与 Prefix-tuning 可以看作是 Prefix Tuning 的简化版本\n\n区别是什么？\n\n1. 适用任务不同\n\na. Prefix-tuning 仅针对 NLG 任务有效，服务于 GPT 架构；\n\nb. 2. 指示微调（ Prompt-tuning ）考虑所有类型的语言模型\n\n2. 添加方式不同\n\na. Prefix-tuning 限定在输入前面添加\n\nb. 指示微调（ Prompt-tuning ）可以在任意位置添加\n\n3. prompt 连续向量添加方式不同\n\na. Prefix-tuning 每一层都添加，保证效果\n\nb. 指示微调（ Prompt-tuning ）可以只在输入层添加\n\n4.2.6 指示微调（ Prompt-tuning ）与 fine-tuning 区别是什么？\n\n1. Fine-tuning 需要改变预训练阶段模型参数，可能带量灾难性遗忘问题\n\n2. 指示微调（ Prompt-tuning ）不改变预训练阶段模型参数，而是通过微调寻找更好的连续 prompt ，来引导已 学习到的知识使用\n\n4.3 P-tuning 篇\n\n4.3.1 为什么需要 P-tuning ？\n\n1. 大模型的 Prompt 构造方式严重影响下游任务的效果 。\n\neg ： GPT 系列 AR 建模在自然语言理解 NLU 任务上效果不好，与 BERT 双向语言模型相比有明显差距；\n\n注： GPT-3 采用人工构造的模版来做上下文学习（ in context learning ），但人工设计的模版的变化特别敏感，加 一个词或者少一个词，或者变动位置都会造成比较大的变化\n\n1. 之前的研究表明 GPT3 使用 prompt 训练方式可以显著提升 few-shot 和 zero-shot 的效果；\n\n2. 自动化搜索模版工作成本也比较高，以前这种离散化的 token 的搜索出来的结果可能并不是最优的，导致性能 不稳定；\n\n4.3.2 P-tuning 思路是什么？\n\n1. 可学习的 Embedding 层设计 。将 Prompt 转换为可学习 Embedding 层；\n\n2. prompt encoder 设计 。用 prompt encoder （由一个双向的 LSTM+ 两层 MLP 组成）的方式来对 Prompt Embedding 进行一层处理，建模伪 token 的相互依赖，并且可以提供一个更好的初始化。\n\n4.3.3 P-tuning 优点是什么？\n\n引入 prompt encoder （由一个双向的 LSTM+ 两层 MLP 组成）来建模伪 token 的相互依赖，并且可以提供一个更好 的初始化 ;\n\n4.3.4 P-tuning 缺点是什么？\n\n1. 复杂性增加 。稍显复杂，看着不太像 prompt 了；\n\n2. 伪 token 编码时是连续的，但在与输入结合时可能是不连续的，中间可能会插入输入\n\n4.4 P-tuning v2 篇\n\n4.4.1 为什么需要 P-tuning v2 ？\n\n如何让 Prompt Tuning 能够在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌 Fine-tuning 的 结果；\n\n4.4.2 P-tuning v2 思路是什么？\n\n1. Deep Prompt Encoding ：采用 Prefix-tuning 的做法，在输入前面的每层加入可微调的 Prompts tokens 作为 输入；\n\n2. 移除了重参数化的编码器（ prefix-tuning 中可选的 MLP 、 p-tuning 中的 LSTM ） ： prefix-tuning 和 ptuning ，通过利用重参数化功能来提高训练速度和鲁棒性，但是该方法对于较小的模型，同时还会影响模型 的表现；\n\n3. 针对不同任务采用不同的提示长度 。提示长度在提示优化方法的超参数搜索中起着核心作用。在实验中，发 现不同的理解任务通常用不同的提示长度来实现其最佳性能，这与 Prefix-Tuning 中的发现一致，不同的文本 生成任务可能有不同的最佳提示长度；\n\n4. 引入多任务学习，先在多任务的 prompt 上进行预训练，然后再适配下游任务；\n\na. 连续提示的随机惯性给优化带来了困难，这可以通过更多的训练数据或与任务相关的无监督预训练来 缓解；\n\nb. 连续提示是跨任务和数据集的特定任务知识的完美载体；\n\n5. 抛弃了 prompt learing 中常用的 verbalizer ，回归到传统的 CLS 和 token label 分类范式 。标签词映射器 （ Label Word Verbalizer ）一直是提示优化的核心组成部分，它将 one-hot 类标签变成有意义的词，以利用预 训练语言模型头。尽管它在 few-shot 设置中具有潜在的必要性，但在全数据监督设置中， Verbalizer 并不是必 须的。它阻碍了提示调优在我们需要无实际意义的标签和句子嵌入的场景中的应用。因此， P-Tuning v2 回归 传统的 CLS 标签分类范式，采用随机初始化的分类头（ Classification Head ）应用于 tokens 之上，以增强通用 性，可以适配到序列标注任务。\n\n4.4.3 P-tuning v2 优点是什么？\n\n1. 在输入前面的每层加入可微调的 Prompts tokens 作为输入 ，优点：\n\na. 更多可学习的参数（从 P-tuning 和 Prompt Tuning 的 0.01% 增加到 0.1%-3% ），同时也足够参数高效；\n\nb. 加入到更深层结构中的 Prompt\n\n能给模型预测带来更直接的影响；\n\n2. 解决了 Prompt Tuning 无法在小模型上有效提升的问题 ；\n\n3. 将 Prompt Tuning 拓展至 NER 等序列标注任务上\n\n4.4.4 P-tuning v2 缺点是什么？\n\n抛弃了 prompt learing 中常用的 verbalizer ，回归到传统的 CLS 和 token label 分类范式，这其实某种程度上弱化了 prompt 的味道\n\n知识星球",
    "file_path": "28-提示学习（Prompting）篇.pdf",
    "create_time": 1763966817,
    "update_time": 1763966817,
    "_id": "doc-59bf9db71eb0feb149a8555e062d5c81"
  }
}